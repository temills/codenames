# Plan for Codenames Study
1. Gather baseline data from human participants with online studies
In the first study, participants will be shown virtual Codenames boards, and will be asked to generate clues and indicate their intended clue-sets
In a subsequent study, participants will be shown virtual Codenames boards, and will be given those clues generated by participants in the first study. They will indicate the clue-set they think is intended by the clue
2. Use word embedding AIs to guess clue-sets based on human-generated clues
Word embedding techniques: word2vec, BERT, word2box
Similarity between words determined by cosine similarity of embeddings
Naive approach
Guess clue-set by taking words on board that are most similar words to clue word
Guess clue-set by taking the group of words whose average embedding is most similar to clue word
3. Use knowledge graph based AI to guess clue-sets based on human-generated clues
Similarity between words determined by strength of link between nodes in knowledge graph
Naive approach
Guess clue-set by taking words on board that are most similar words to clue word
Guess clue-set by taking the group of words whose average embedding is most similar to clue word
4. Combined knowledge graph / word embedding AI
Determine word similarity through average of knowledge graph and word embedding similarity scores
Use knowledge graph links to determine clue-set options, and word embedding cosine similarity to choose among options
5. Evaluate and compare performance of AIs and human performance
Evaluate based on proportion of words from clue-set guessed
Also consider if any next-best options as determined by AIs were in clue-set
Likely to have limited success with word embeddings
If conceptual knowledge from knowledge graphs does not fill in some of these performance gaps, there is an interesting question of what sort of knowledge is missing
6. Potential next steps
Create a new embedding to address observed limitations
Incorporate Rational Speech Act recursive reasoning
